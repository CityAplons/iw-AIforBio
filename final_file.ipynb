{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from numpy import linalg as LA\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_mutation(sequence,position,current):\n",
    "    sequence = str(sequence)[:int(position)]+str(current)+str(sequence)[int(position)+1:]\n",
    "    return sequence\n",
    "def read_data(file_name):\n",
    "    conn = sql.connect(file_name)\n",
    "    cursor = conn.cursor()\n",
    "    types = [str,str,int,str,float,float,float]\n",
    "    names = [\"sequence\",\"current\",\"position\",\"mutation\",\"ddG\",\"PH\",\"Temp\"]\n",
    "    results = {names[i]:[] for i in range(len(names))}\n",
    "    for row in cursor.execute(\"SELECT * FROM dataset\"):\n",
    "        row = list(row)\n",
    "        row[2] = str(int(row[2])-1)\n",
    "        for i in range(len(names)):\n",
    "            results[names[i]].append(types[i](row[i]))\n",
    "    result = pd.DataFrame(results)\n",
    "    conn.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetry_add(data_set):\n",
    "    inversed = data_set.copy()\n",
    "    inversed.mutation,inversed.current = inversed.current.apply(lambda x:x),inversed.mutation.apply(lambda x:x)\n",
    "    inversed['ddG'] = inversed.ddG.apply(lambda x: -x)\n",
    "    inversed['sequence'] = inversed.apply(lambda x: inverse_mutation(x['sequence'],x['position'],x['current']),axis =1)\n",
    "    return inversed.merge(data_set,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(data_set):\n",
    "    number_plus = len(data_set[data_set.ddG > 0])\n",
    "    number_minus = len(data_set[data_set.ddG < 0])\n",
    "    multiply = int(number_minus/number_plus)\n",
    "    add = number_minus-number_plus*multiply\n",
    "    plus = data_set[data_set.ddG > 0].copy()\n",
    "    result = {y:map(lambda x: x[0],plus[[y]].values)*multiply+map(lambda x: x[0],plus[[y]].values)[:add] for y in map(str,plus.columns)}\n",
    "    result = pd.DataFrame(result)\n",
    "    all_else = data_set[data_set.ddG <=0].copy()\n",
    "    return result.merge(all_else,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbour(sequence,position,shift):\n",
    "    if (position + shift > len(sequence)-1 or position + shift < 0):\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return sequence[position+shift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_true_false(label, true_label):\n",
    "    count_true = 0\n",
    "    count_all = 0\n",
    "    for i in range(len(label)):\n",
    "        count_all += 1\n",
    "        if (np.sign(true_label[i]) == np.sign(label[i])):\n",
    "            count_true += 1\n",
    "    return float(count_true)/count_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_symmetry(estimator,test_data,test_labels):\n",
    "    columns = map(str,test_data.columns)\n",
    "    inversed_test_data = test_data.copy()\n",
    "    inversed_test_data.current,inversed_test_data.mutation = inversed_test_data.mutation.apply(lambda x: x),inversed_test_data.current.apply(lambda x: x)\n",
    "    inversed_labels = estimator.predict(inversed_test_data)\n",
    "    test_labels = np.array(test_labels)\n",
    "    inversed_labels = np.array(inversed_labels)\n",
    "    vector = test_labels+inversed_labels\n",
    "    return np.sum(map(abs,vector))/len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate():\n",
    "    #read dataset\n",
    "    raw_data = read_data(\"iwdb.sqlite\")\n",
    "    #edit new features\n",
    "    number_neighbours = 5\n",
    "    for i in range(1,number_neighbours+1):\n",
    "        raw_data['Left'+str(i)] = raw_data.apply(lambda row: neighbour(row['sequence'],row['position'],-(i)),axis=1)\n",
    "        raw_data['Right'+str(i)] = raw_data.apply(lambda row: neighbour(row['sequence'],row['position'],(i)),axis=1)\n",
    "    #shuffle data\n",
    "    raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "    #change symbols in features to int values\n",
    "    inputting = 'A B C D E F G H I J K L M N O P Q R S T U V W X Y Z 0'\n",
    "    symbols = inputting.split(' ')\n",
    "    numerics = [i for i in range(len(symbols))]\n",
    "    categorical = ['current','mutation']+['Left'+str(i) for i in range(1,number_neighbours+1)]+['Right'+str(i) for i in range(1,number_neighbours+1)]\n",
    "    for item in categorical:\n",
    "        raw_data[item] = raw_data[item].apply(lambda x: numerics[symbols.index(x)])\n",
    "    #make train and test data\n",
    "    train_size = 0.7\n",
    "    size = int(len(raw_data)*train_size)\n",
    "    train_data = raw_data.iloc[:size]\n",
    "    test_data = raw_data.iloc[size:]\n",
    "    train_data = symmetry_add(train_data)\n",
    "    #train_data = over_sampling(train_data)\n",
    "    train_labels = train_data['ddG'].values\n",
    "    train_data = train_data.drop(['ddG','sequence'],axis=1)\n",
    "    test_labels = test_data['ddG'].values\n",
    "    test_data = test_data.drop(['ddG','sequence'],axis=1)\n",
    "    #make foundation for pipeline\n",
    "    binary_data_columns = ['holiday', 'workingday']\n",
    "    binary_data_indices = np.array([(column in binary_data_columns) for column in train_data.columns], dtype = bool)\n",
    "    categorical_data_indices = np.array([(column in categorical) for column in train_data.columns], dtype = bool)\n",
    "    numeric_data_columns = ['Temp', 'PH', 'position']\n",
    "    numeric_data_indices = np.array([(column in numeric_data_columns) for column in train_data.columns], dtype = bool)\n",
    "    #creat regressor\n",
    "    regr = RandomForestRegressor(random_state = 0, max_depth = 20, n_estimators = 500)\n",
    "    #regr = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "    estimator = pipeline.Pipeline(steps = [       \n",
    "        ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                #binary\n",
    "                ('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "                    \n",
    "                #numeric\n",
    "                ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "                     ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices]))\n",
    "                            ])),\n",
    "        \n",
    "                #categorical\n",
    "                ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "                    ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices]))            \n",
    "                            ])),\n",
    "            ])),\n",
    "        ('model_fitting', regr)\n",
    "        ]\n",
    "    )\n",
    "    # make prediction\n",
    "    estimator.fit(train_data,train_labels)\n",
    "    predictions = estimator.predict(test_data)\n",
    "    #save\n",
    "    #with open('my_dumped_classifier.pkl', 'wb') as fid:\n",
    "    #    cPickle.dump(regr, fid)   \n",
    "    #print parameters\n",
    "    text =\"mean absolute error: \" + str(metrics.mean_absolute_error(test_labels,predictions))+\"\\naccuracy: \" + str(test_true_false(predictions,test_labels))+\"\\nmean absolute error symmetry: \"+str(test_symmetry(estimator,test_data,test_labels))\n",
    "    print(text)\n",
    "    return estimator\n",
    "    #test_load(test_data,test_labels,binary_data_indices,numeric_data_indices,categorical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: 1.073951644891202\n",
      "accuracy: 0.71686746988\n",
      "mean absolute error symmetry: 1.0709103489394662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_processing', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('binary_variables_processing', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "          func=<function <lambda> at 0x000000000CF63898>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y=...imators=500, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('weights.pkl', 'wb') as fid:\n",
    "#    cPickle.dump(regr, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load it again\n",
    "def test_load(binary_data_indices,numeric_data_indices,categorical_data_indices):\n",
    "    with open('weights.pkl', 'rb') as fid:\n",
    "        gnb_loaded = cPickle.load(fid)\n",
    "    estimator = pipeline.Pipeline(steps = [       \n",
    "            ('feature_processing', pipeline.FeatureUnion(transformer_list = [        \n",
    "                    #binary\n",
    "                    ('binary_variables_processing', preprocessing.FunctionTransformer(lambda data: data[:, binary_data_indices])), \n",
    "                    \n",
    "                    #numeric\n",
    "                    ('numeric_variables_processing', pipeline.Pipeline(steps = [\n",
    "                         ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, numeric_data_indices]))\n",
    "                                ])),\n",
    "        \n",
    "                    #categorical\n",
    "                    ('categorical_variables_processing', pipeline.Pipeline(steps = [\n",
    "                        ('selecting', preprocessing.FunctionTransformer(lambda data: data[:, categorical_data_indices]))            \n",
    "                                ])),\n",
    "                ])),\n",
    "            ('model_fitting', gnb_loaded)\n",
    "            ]\n",
    "        )\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(sequence,current,position,mutation,ph = 8.0,temp=37.):\n",
    "    number_neighbours = 5\n",
    "    columns = ['sequence','current','position','mutation','PH','Temp']\n",
    "    data = [sequence,current,position,mutation,ph,temp]\n",
    "    test_data = {columns[i]:[data[i]] for i in range(len(columns))}\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    for i in range(1,number_neighbours+1):\n",
    "        test_data['Left'+str(i)] = test_data.apply(lambda row: neighbour(row['sequence'],row['position'],-(i)),axis=1)\n",
    "        test_data['Right'+str(i)] = test_data.apply(lambda row: neighbour(row['sequence'],row['position'],(i)),axis=1)\n",
    "    test_data = test_data.drop(['sequence'],axis=1)\n",
    "    categorical = ['current','mutation']+['Left'+str(i) for i in range(1,number_neighbours+1)]+['Right'+str(i) for i in range(1,number_neighbours+1)]\n",
    "    binary_data_columns = ['g']\n",
    "    binary_data_indices = np.array([(column in binary_data_columns) for column in test_data.columns], dtype = bool)\n",
    "    categorical_data_indices = np.array([(column in categorical) for column in test_data.columns], dtype = bool)\n",
    "    numeric_data_columns = ['Temp', 'PH', 'position']\n",
    "    numeric_data_indices = np.array([(column in numeric_data_columns) for column in test_data.columns], dtype = bool)\n",
    "    inputting = 'A B C D E F G H I J K L M N O P Q R S T U V W X Y Z 0'\n",
    "    symbols = inputting.split(' ')\n",
    "    numerics = [i for i in range(len(symbols))]\n",
    "    for item in categorical:\n",
    "        test_data[item] = test_data[item].apply(lambda x: numerics[symbols.index(x)])\n",
    "    estimator = calculate()\n",
    "    result = estimator.predict(test_data)\n",
    "    return result\n",
    "#print(\"ddG = \"+ str(prediction(\"A\",\"C\",5,\"G\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
